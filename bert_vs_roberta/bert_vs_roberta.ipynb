{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80xvsmaVlrwx"
   },
   "source": [
    "#Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (18.1.0)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting optuna\n",
      "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.34.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.16.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.43)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.7)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Downloading transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pyarrow, colorlog, pandas, alembic, optuna, transformers, evaluate\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 18.1.0\n",
      "    Uninstalling pyarrow-18.1.0:\n",
      "      Successfully uninstalled pyarrow-18.1.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.2\n",
      "    Uninstalling pandas-2.2.2:\n",
      "      Successfully uninstalled pandas-2.2.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.55.2\n",
      "    Uninstalling transformers-4.55.2:\n",
      "      Successfully uninstalled transformers-4.55.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n",
      "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
      "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
      "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed alembic-1.16.4 colorlog-6.9.0 evaluate-0.4.5 optuna-4.5.0 pandas-2.3.2 pyarrow-21.0.0 transformers-4.55.4\n"
     ]
    }
   ],
   "source": [
    "!pip install -U datasets transformers accelerate pandas pyarrow chardet nltk spacy evaluate optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.8.0\n",
      "  Downloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting torchvision==0.23.0\n",
      "  Downloading torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio==2.8.0\n",
      "  Downloading torchaudio-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n",
      "Collecting transformers==4.44.2\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (2025.3.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch==2.8.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch==2.8.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch==2.8.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch==2.8.0)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch==2.8.0)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch==2.8.0)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch==2.8.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch==2.8.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch==2.8.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (0.7.1)\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from torch==2.8.0)\n",
      "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch==2.8.0)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch==2.8.0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch==2.8.0)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (3.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.23.0) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.23.0) (11.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.34.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.6.2)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.2)\n",
      "  Downloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (4.67.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.3.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (21.0.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (1.1.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.8.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.8.0) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.9/887.9 MB\u001b[0m \u001b[31m838.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m123.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m877.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m129.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m852.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, tokenizers, nvidia-cusolver-cu12, transformers, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
      "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.19.3\n",
      "    Uninstalling nvidia-nccl-cu12-2.19.3:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
      "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
      "  Attempting uninstall: nvidia-cufile-cu12\n",
      "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
      "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
      "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
      "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
      "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n",
      "    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.4\n",
      "    Uninstalling tokenizers-0.21.4:\n",
      "      Successfully uninstalled tokenizers-0.21.4\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
      "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.55.4\n",
      "    Uninstalling transformers-4.55.4:\n",
      "      Successfully uninstalled transformers-4.55.4\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.2\n",
      "    Uninstalling torch-2.2.2:\n",
      "      Successfully uninstalled torch-2.2.2\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.17.2\n",
      "    Uninstalling torchvision-0.17.2:\n",
      "      Successfully uninstalled torchvision-0.17.2\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.2.2\n",
      "    Uninstalling torchaudio-2.2.2:\n",
      "      Successfully uninstalled torchaudio-2.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
      "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 tokenizers-0.19.1 torch-2.8.0 torchaudio-2.8.0 torchvision-0.23.0 transformers-4.44.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "90bd9688c29342b79b7d4fd26fc06996",
       "pip_warning": {
        "packages": [
         "nvidia",
         "tokenizers",
         "torch",
         "torchgen",
         "transformers"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 transformers==4.44.2 evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tN317b2-lwen"
   },
   "source": [
    "#Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import re,string\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import nltk\n",
    "import optuna\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.8.0+cu126\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "print('Torch:', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yx3tbwTkly3P"
   },
   "source": [
    "#Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492c01081cf7473eb9d33a46461e182d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e609b584cf413d82cc80994d6bce28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbb59b9b7e64b5ab7d1d5b46158de71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f9a0b78a5a481d90a0dfa8fd8acdfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9153d99e4cff49fbb71ed6e04c97ebec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba9965afce4433da1db944f65acc352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854a244e936b4cea9219465dfdba2389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    unsupervised: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#From huggingface\n",
    "dataset = load_dataset('imdb')\n",
    "print(dataset)\n",
    "\n",
    "#Custom\n",
    "#dataset = load_dataset(\"csv\",data_files={'data':'custom.csv'})['data']\n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 5000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    unsupervised: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#shortening the dataset from 25k train samples to only 5k for faster training.\n",
    "dataset[\"train\"] = dataset[\"train\"].shuffle(seed=42).select(range(5000))\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0g4lx6M5q0gb"
   },
   "source": [
    "#Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop nulls and fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_url=True\n",
    "re_html=True\n",
    "re_stopwords=False\n",
    "lower=True\n",
    "re_punc=True\n",
    "\n",
    "urls = re.compile(r\"(www\\.\\S+|https?://\\S+)\")\n",
    "htmls = re.compile(r\"(<.*?>)\")\n",
    "stopwords = set(stopwords.words(\"english\")) if re_stopwords else set()\n",
    "punct = str.maketrans(\"\",\"\",string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(x):\n",
    "  if re_url:\n",
    "    x=urls.sub(\" \",x)\n",
    "  if re_html:\n",
    "    x=htmls.sub(\" \",x)\n",
    "  if lower:\n",
    "    x=x.lower()\n",
    "  if re_stopwords:\n",
    "    x= \" \".join([w for w in x.split() if w not in stopwords])\n",
    "  if re_punc:\n",
    "    x=x.translate(punct)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_clean(batch):\n",
    "  return {\"text\":[clean_text(x) for x in batch[\"text\"]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55bad6c7e31437ea5789ffb5b4e0ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c620ec8c4e44f8bdb16cd0a876f7b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b51455a8ad4caeb3cdef77ed013999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes Profiler looks crispy Fortier looks classic Profiler plots are quite simple Fortiers plot are far more complicated Fortier looks more like Prime Suspect if we have to spot similarities The main character is weak and weirdo but have clairvoyance People like to compare to judge to evaluate How about just enjoying Funny thing too people writing Fortier looks American but on the other hand arguing they prefer American series  Maybe its the language or the spirit but I think this series is more English than American By the way the actors are really good and funny The acting is not superficial at all', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "dataset=dataset.map(apply_clean,batched=True)\n",
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ry4v5ey-tbiJ"
   },
   "source": [
    "#Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_1='bert-base-uncased'\n",
    "model_name_2='roberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015a57b44264419e9514cd1d33d82d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8434f08bbc6c419198cbdbad22469a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59701a9278044ed5b095a52e2e415241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556c5c20180d4aa99d4b234d9a327013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd46280366a43e3a4b5cb2607f12e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90182e4f3fbe423bbdd4e1f34f6a7a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f66d47fa034ce99b0f84f7ae7e40e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba0881d6eb84ff7be0e7a39c760a57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4190729dbf7f4c18b74803713f1b4308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_bert=AutoTokenizer.from_pretrained(model_name_1,use_fast=True)\n",
    "tokenizer_roberta=AutoTokenizer.from_pretrained(model_name_2,use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 256\n",
    "\n",
    "def tokenize_bert(batch):\n",
    "  return tokenizer_bert(batch['text'], truncation=True, max_length=max_len)\n",
    "\n",
    "def tokenize_roberta(batch):\n",
    "  return tokenizer_roberta(batch['text'], truncation=True, max_length=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c8d9563a0b45ffacd9ae5a682a38e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ebee30927945b0ba9d40ad36492e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33bdf85166f40f78e6e09f22e86ae44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': [1, 1, 0], 'input_ids': [[101, 2045, 2003, 2053, 7189, 2012, 2035, 2090, 3481, 3771, 1998, 6337, 2099, 2021, 1996, 2755, 2008, 2119, 2024, 2610, 2186, 2055, 6355, 6997, 6337, 2099, 3504, 15594, 2100, 3481, 3771, 3504, 4438, 6337, 2099, 14811, 2024, 3243, 3722, 3481, 10136, 5436, 2024, 2521, 2062, 8552, 3481, 3771, 3504, 2062, 2066, 3539, 8343, 2065, 2057, 2031, 2000, 3962, 12319, 1996, 2364, 2839, 2003, 5410, 1998, 6881, 2080, 2021, 2031, 17936, 6767, 7054, 3401, 2111, 2066, 2000, 12826, 2000, 3648, 2000, 16157, 2129, 2055, 2074, 9107, 6057, 2518, 2205, 2111, 3015, 3481, 3771, 3504, 2137, 2021, 2006, 1996, 2060, 2192, 9177, 2027, 9544, 2137, 2186, 2672, 2049, 1996, 2653, 2030, 1996, 4382, 2021, 1045, 2228, 2023, 2186, 2003, 2062, 2394, 2084, 2137, 2011, 1996, 2126, 1996, 5889, 2024, 2428, 2204, 1998, 6057, 1996, 3772, 2003, 2025, 23105, 2012, 2035, 102], [101, 2023, 3185, 2003, 1037, 2307, 1996, 5436, 2003, 2200, 2995, 2000, 1996, 2338, 2029, 2003, 1037, 4438, 2517, 2011, 2928, 24421, 1996, 3185, 4627, 1997, 2007, 1037, 3496, 2073, 9180, 10955, 1037, 2299, 2007, 1037, 9129, 1997, 4268, 2170, 2043, 2017, 24646, 2497, 2115, 11756, 2006, 1996, 4231, 2009, 15537, 2033, 1997, 19643, 2015, 2299, 2152, 8069, 2009, 2003, 4569, 1998, 28676, 1996, 2189, 2003, 2307, 2802, 1998, 2026, 5440, 2299, 2003, 7042, 2011, 1996, 2332, 9180, 17620, 14282, 1998, 2909, 7842, 22772, 12312, 5974, 3452, 1037, 2307, 2155, 3185, 2030, 2130, 1037, 2307, 3058, 3185, 2023, 2003, 1037, 3185, 2017, 2064, 3422, 2058, 1998, 2058, 2153, 1996, 4615, 2209, 2011, 1054, 8747, 2850, 13779, 2003, 9882, 1045, 2293, 2023, 3185, 2065, 2017, 4669, 6266, 23686, 1999, 1996, 2457, 15333, 6238, 2059, 2017, 2097, 5791, 2066, 2023, 3185, 102], [101, 2577, 1052, 2522, 26212, 13122, 8223, 5092, 2034, 2668, 2112, 2462, 2003, 5760, 4299, 3993, 8873, 3363, 3672, 1996, 2142, 2163, 4415, 2134, 2102, 2663, 1996, 2162, 1999, 5148, 2027, 3303, 4053, 2000, 2023, 2406, 3458, 1996, 10047, 22974, 22966, 1998, 2023, 3185, 4247, 1996, 8867, 2466, 1997, 1996, 2821, 6499, 7036, 3548, 1996, 2069, 2919, 4364, 2020, 1996, 4177, 1997, 1996, 3842, 2040, 2081, 2023, 2162, 4148, 1996, 2839, 1997, 8223, 5092, 2003, 3819, 2000, 5060, 2023, 2002, 2003, 5186, 14314, 2022, 5302, 6962, 2008, 3915, 25531, 6962, 2134, 2102, 9120, 1998, 8439, 1996, 10106, 1997, 1996, 2309, 5268, 2021, 2038, 2498, 2021, 29245, 2005, 2877, 3738, 1998, 8801, 2066, 2296, 2143, 2008, 6985, 2015, 1996, 2162, 1041, 2290, 2057, 2020, 3548, 2036, 2023, 2028, 26777, 1996, 2342, 2000, 2507, 1037, 4012, 28139, 10222, 19307, 3114, 2005, 1996, 8147, 1999, 2148, 4021, 1998, 2005, 2008, 3043, 2036, 1996, 3114, 2005, 2296, 2309, 3915, 25531, 2319, 5268, 2008, 2001, 2045, 2612, 8223, 5092, 4152, 2000, 2202, 7195, 2005, 1996, 8710, 1997, 1037, 2878, 3842, 2009, 2052, 2031, 2042, 2488, 2000, 2147, 2006, 2129, 2000, 3066, 2007, 1996, 5758, 2738, 2084, 16081, 2075, 2068, 2079, 2057, 2131, 2000, 2663, 2023, 2051, 2748, 2017, 2079, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "tokenized_bert = dataset.map(tokenize_bert, batched=True, remove_columns=[\"text\"])\n",
    "print(tokenized_bert[\"train\"][0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9c92fb7e314c4cbb73e069de94efdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29495447b5d5451e9a6b3fe079c9f71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844179753d3a497891de2d19af0ca996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': [1, 1, 0], 'input_ids': [[0, 970, 16, 117, 9355, 23, 70, 227, 3339, 906, 8, 6853, 10329, 53, 5, 754, 14, 258, 32, 249, 651, 59, 4153, 3474, 6853, 10329, 1326, 32042, 3339, 906, 1326, 4187, 6853, 10329, 21258, 32, 1341, 2007, 3339, 4733, 6197, 32, 444, 55, 6336, 3339, 906, 1326, 55, 101, 1489, 10471, 13771, 114, 52, 33, 7, 1514, 20097, 20, 1049, 2048, 16, 3953, 8, 7735, 139, 53, 33, 3741, 2456, 35246, 2389, 1806, 101, 7, 8933, 7, 1679, 7, 10516, 1336, 59, 95, 6218, 31906, 631, 350, 82, 2410, 3339, 906, 1326, 470, 53, 15, 5, 97, 865, 7594, 51, 6573, 470, 651, 1437, 5359, 63, 5, 2777, 50, 5, 4780, 53, 38, 206, 42, 651, 16, 55, 2370, 87, 470, 870, 5, 169, 5, 5552, 32, 269, 205, 8, 6269, 20, 3501, 16, 45, 34501, 23, 70, 2], [0, 713, 1569, 16, 10, 372, 20, 6197, 16, 182, 1528, 7, 5, 1040, 61, 16, 10, 4187, 1982, 30, 1190, 34878, 20, 1569, 2012, 9, 19, 10, 1310, 147, 22216, 22707, 10, 2214, 19, 10, 6900, 9, 1159, 373, 77, 47, 35672, 110, 14934, 15, 5, 6950, 85, 14236, 162, 9, 8356, 415, 5079, 2214, 755, 13583, 293, 24, 16, 1531, 8, 21504, 20, 3920, 16, 372, 1328, 8, 127, 2674, 2214, 16, 26115, 30, 5, 1745, 22216, 741, 154, 15656, 8, 5348, 16833, 4740, 16833, 424, 1688, 384, 21119, 1250, 10, 372, 284, 1569, 50, 190, 10, 372, 10566, 1569, 152, 16, 10, 1569, 47, 64, 1183, 81, 8, 81, 456, 20, 19169, 702, 30, 8778, 11192, 22273, 16, 12058, 38, 657, 42, 1569, 318, 47, 6640, 6937, 7120, 242, 11, 5, 837, 22198, 1334, 172, 47, 40, 2299, 101, 42, 1569, 2], [0, 25395, 221, 11013, 9244, 366, 3513, 3983, 1234, 11391, 4657, 3082, 16, 8309, 2813, 2650, 29238, 1757, 20, 315, 532, 2563, 46405, 339, 5, 997, 11, 5490, 252, 1726, 1880, 7, 42, 247, 1684, 5, 36749, 8, 42, 1569, 1388, 5, 25310, 527, 9, 5, 14223, 2527, 7850, 3878, 20, 129, 1099, 1669, 58, 5, 917, 9, 5, 1226, 54, 156, 42, 997, 1369, 20, 2048, 9, 3513, 3983, 16, 1969, 7, 3120, 42, 91, 16, 2778, 22908, 28, 4992, 1253, 14, 2805, 30998, 1253, 46405, 5478, 8, 3379, 5, 9270, 9, 5, 881, 9716, 53, 34, 1085, 53, 27948, 13, 981, 1024, 8, 3770, 2011, 358, 822, 14, 24951, 5, 997, 29230, 166, 18258, 28334, 67, 42, 65, 29879, 5, 240, 7, 492, 10, 32616, 4748, 1219, 13, 5, 4921, 11, 391, 1817, 178, 13, 14, 948, 67, 5, 1219, 13, 358, 881, 2805, 30998, 260, 9716, 14, 21, 89, 2978, 3513, 3983, 1516, 7, 185, 13543, 13, 5, 9308, 9, 10, 1086, 1226, 85, 74, 33, 57, 357, 7, 173, 15, 141, 7, 432, 19, 5, 6180, 1195, 87, 38919, 106, 1832, 52, 120, 7, 339, 42, 86, 3216, 47, 109, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "tokenized_roberta = dataset.map(tokenize_roberta, batched=True, remove_columns=[\"text\"])\n",
    "print(tokenized_roberta[\"train\"][0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5zZZv7DvdSG"
   },
   "source": [
    "#Padding & Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator_bert = DataCollatorWithPadding(tokenizer=tokenizer_bert)\n",
    "data_collator_roberta = DataCollatorWithPadding(tokenizer=tokenizer_roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_bert = DataLoader(tokenized_bert[\"train\"], batch_size=8, collate_fn=data_collator_bert, shuffle=True)\n",
    "train_loader_roberta = DataLoader(tokenized_roberta[\"train\"], batch_size=8, collate_fn=data_collator_roberta, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([8, 256])\n",
      "token_type_ids torch.Size([8, 256])\n",
      "attention_mask torch.Size([8, 256])\n",
      "labels torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader_bert))\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([8, 256])\n",
      "attention_mask torch.Size([8, 256])\n",
      "labels torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader_roberta))\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a1f0951e42479f96d0f866090c2cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9524a3a1ceb64944bcf533b58c678474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e849ce07f3d34deeb8fd762c8a32f0ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ready & saved!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00e59a067614cf99a1e52c0691656b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f02fe8211245a190f437e963c04f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8f507adfe04900a8df10fd0560c227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ready & saved!\n"
     ]
    }
   ],
   "source": [
    "tokenized_bert.save_to_disk(\"roberta_dataset\")\n",
    "print(\"Dataset ready & saved!\")\n",
    "\n",
    "tokenized_roberta.save_to_disk(\"bert_dataset\")\n",
    "print(\"Dataset ready & saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pFr0hPIvJYa"
   },
   "source": [
    "#Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fd2a07f3bb4516ab1a052203a71101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f862a173b0e46e1a33d45bbce293c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_bert = AutoModelForSequenceClassification.from_pretrained(model_name_1, num_labels=2)\n",
    "model_roberta = AutoModelForSequenceClassification.from_pretrained(model_name_2, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Px4VUWTYvM5B"
   },
   "source": [
    "#Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6286e5676fb845cc93ba5ddb39bb0a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179afde7f1ed4c11acfc05d00327a47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": acc_metric.compute(predictions=preds, references=labels),\n",
    "        \"f1\": f1_metric.compute(predictions=preds, references=labels, average=\"weighted\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keoyR7_5vO3K"
   },
   "source": [
    "#Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, tokenizer, train_dataset, val_dataset, model_name):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./{model_name}_results\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        load_best_model_at_end=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    return trainer, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfJ0bocyvXpr"
   },
   "source": [
    "#Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-2561820757.py:12: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33makhyar\u001b[0m (\u001b[33makhyar-university-of-engineering-and-technology-lahore\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250824_142437-yqqtxiyf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/akhyar-university-of-engineering-and-technology-lahore/huggingface/runs/yqqtxiyf' target=\"_blank\">sparkling-firefly-8</a></strong> to <a href='https://wandb.ai/akhyar-university-of-engineering-and-technology-lahore/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/akhyar-university-of-engineering-and-technology-lahore/huggingface' target=\"_blank\">https://wandb.ai/akhyar-university-of-engineering-and-technology-lahore/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/akhyar-university-of-engineering-and-technology-lahore/huggingface/runs/yqqtxiyf' target=\"_blank\">https://wandb.ai/akhyar-university-of-engineering-and-technology-lahore/huggingface/runs/yqqtxiyf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='939' max='939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [939/939 32:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.284411</td>\n",
       "      <td>{'accuracy': 0.89016}</td>\n",
       "      <td>{'f1': 0.8899003769855999}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.342300</td>\n",
       "      <td>0.286813</td>\n",
       "      <td>{'accuracy': 0.90524}</td>\n",
       "      <td>{'f1': 0.9052037315543888}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.342300</td>\n",
       "      <td>0.377459</td>\n",
       "      <td>{'accuracy': 0.90584}</td>\n",
       "      <td>{'f1': 0.9058161294370677}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.89016}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.8899003769855999}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.90524}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9052037315543888}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.90584}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9058161294370677}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 06:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.89016}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.8899003769855999}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "/tmp/ipython-input-2561820757.py:12: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='939' max='939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [939/939 32:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.231491</td>\n",
       "      <td>{'accuracy': 0.92208}</td>\n",
       "      <td>{'f1': 0.9220105562027131}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.292400</td>\n",
       "      <td>0.293062</td>\n",
       "      <td>{'accuracy': 0.92724}</td>\n",
       "      <td>{'f1': 0.9271869192641435}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.292400</td>\n",
       "      <td>0.306527</td>\n",
       "      <td>{'accuracy': 0.93124}</td>\n",
       "      <td>{'f1': 0.9312371481569877}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.92208}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9220105562027131}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.92724}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9271869192641435}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.93124}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9312371481569877}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 06:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.92208}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9220105562027131}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    }
   ],
   "source": [
    "bert_trainer, bert_metrics = train_model(model_bert, tokenizer_bert, tokenized_bert[\"train\"], tokenized_bert[\"test\"], \"bert\")\n",
    "roberta_trainer, roberta_metrics = train_model(model_roberta, tokenizer_roberta, tokenized_roberta[\"train\"], tokenized_roberta[\"test\"], \"roberta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGR-duwdHs_o"
   },
   "source": [
    "#Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT metrics: {'eval_loss': 0.28441062569618225, 'eval_accuracy': {'accuracy': 0.89016}, 'eval_f1': {'f1': 0.8899003769855999}, 'eval_runtime': 394.5575, 'eval_samples_per_second': 63.362, 'eval_steps_per_second': 7.92, 'epoch': 3.0}\n",
      "RoBERTa metrics: {'eval_loss': 0.23149074614048004, 'eval_accuracy': {'accuracy': 0.92208}, 'eval_f1': {'f1': 0.9220105562027131}, 'eval_runtime': 379.7096, 'eval_samples_per_second': 65.84, 'eval_steps_per_second': 8.23, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"BERT metrics:\", bert_metrics)\n",
    "print(\"RoBERTa metrics:\", roberta_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = [\"BERT\", \"RoBERTa\"]\n",
    "\n",
    "accuracies = [bert_metrics[\"eval_accuracy\"][\"accuracy\"], roberta_metrics[\"eval_accuracy\"][\"accuracy\"]]\n",
    "f1s = [bert_metrics[\"eval_f1\"][\"f1\"], roberta_metrics[\"eval_f1\"][\"f1\"]]\n",
    "\n",
    "x = range(len(models))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar([i - width/2 for i in x], accuracies, width=width, label=\"Accuracy\")\n",
    "plt.bar([i + width/2 for i in x], f1s, width=width, label=\"F1 Score\")\n",
    "\n",
    "plt.xticks(x, models)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"BERT vs RoBERTa on Emotion Detection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
