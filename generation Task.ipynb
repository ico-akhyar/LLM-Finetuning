{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMf3LZOmzruG/yPP/71UTDU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"QcssLFcnqYMm"},"outputs":[],"source":["import re\n","from datasets import load_dataset\n","from transformers import AutoTokenizer, DataCollatorForLanguageModeling, AutoModelForCausalLM, Trainer, TrainingArguments\n","import torch\n","print('Torch:', torch.__version__)\n","print('CUDA available:', torch.cuda.is_available())"]},{"cell_type":"code","source":["dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n","print(dataset)\n","\n","## Custom TXT/CSV\n","# dataset = load_dataset(\"text\", data_files={\"train\": \"train.txt\", \"test\": \"test.txt\"})"],"metadata":{"id":"-EqgwEZAqkJ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def clean_text(s: str) -> str:\n","    s = re.sub(r\"\\s+\", \" \", s).strip()\n","    return s\n","\n","def apply_clean(batch):\n","    return {\"text\": [clean_text(x) for x in batch[\"text\"]]}\n","\n","dataset = dataset.map(apply_clean, batched=True)"],"metadata":{"id":"CeywtsJAqlME"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_ckpt = \"gpt2\"\n","tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n","if tokenizer.pad_token is None:\n","    tokenizer.pad_token = tokenizer.eos_token\n","\n","def tok_fn(batch):\n","    return tokenizer(batch[\"text\"], truncation=True, max_length=128)\n","\n","tokenized = dataset.map(tok_fn, batched=True, remove_columns=[\"text\"])"],"metadata":{"id":"u-Gd0EPvqrd6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"],"metadata":{"id":"b8JRxOWSqy8r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = AutoModelForCausalLM.from_pretrained(model_ckpt)\n","\n","args = TrainingArguments(\n","    output_dir=\"gpt2_out\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=4,\n","    num_train_epochs=1,\n","    logging_dir=\"logs\",\n","    save_strategy=\"epoch\",\n","    fp16=torch.cuda.is_available()\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=args,\n","    train_dataset=tokenized[\"train\"].select(range(5000)),\n","    eval_dataset=tokenized[\"validation\"].select(range(1000)),\n","    tokenizer=tokenizer,\n","    data_collator=collator\n",")"],"metadata":{"id":"hqP_H3hiq1-3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"-0jZFpz2q245"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save_pretrained(\"generator_model\")\n","tokenizer.save_pretrained(\"generator_model\")\n","print(\"âœ… GPT-2 trained & saved!\")"],"metadata":{"id":"Fr0JPL6Lq6Rf"},"execution_count":null,"outputs":[]}]}